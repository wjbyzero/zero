import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.metrics import roc_auc_score,accuracy_score,precision_score,recall_score
import warnings
warnings.filterwarnings('ignore')
import os
#读取数据

data=pd.read_csv('creditcard.csv')
#查看数据结构
data.head()
data.shape
data.isnull().sum()
data['Amount'].hist()
#交易金额存在明显的偏态分布
#查看交易金额的分布情况
sns.distplot(data['Amount'][data['Class']==1],bins=50,color='red')
sns.distplot(data['Amount'][data['Class']==0],bins=50,color='blue')
plt.show()
#对交易金额进行纠偏
data['Amount']=data['Amount'].map(lambda x: np.log(x) if x>0 else 0)
#查看纠偏后的数据分布
data['Amount'].hist()
#再次查看不同样本的交易金额数据分布
sns.distplot(data['Amount'][data['Class']==1],bins=50,color='red')
sns.distplot(data['Amount'][data['Class']==0],bins=50,color='blue')
plt.show()
#查看时间分布情况
data['Time'].hist()
timedelta=pd.to_timedelta(data['Time'],unit='s')
data['Time_min']=(timedelta.dt.components.minutes).astype(int)
data['Time_hour']=(timedelta.dt.components.hours).astype(int)
#分别查看新增的时间特征与是否有欺诈风险的关系
plt.figure(figsize=(12,5))
sns.distplot(data[data['Class']==0]['Time_hour'],color='blue')
sns.distplot(data[data['Class']==1]['Time_hour'],color='red')
plt.title('Fraud x Normal Transaction by Hours',fontsize=17)
plt.xlim([-1,25])
plt.show()
plt.figure(figsize=(12,5))
sns.distplot(data[data['Class']==0]['Time_min'],color='blue')
sns.distplot(data[data['Class']==1]['Time_min'],color='red')
plt.title('Fraud x Normal Transaction by Minutes',fontsize=17)
plt.xlim([0,60])
plt.show()
#查看其他特征的数据分布情况
columns=[f'V{i}' for i in range(1,29)]
grid=gridspec.GridSpec(14,2)
plt.figure(figsize=(15,20*4))

for n,col in enumerate(columns):
    ax=plt.subplot(grid[n])
    sns.distplot(data[col][data['Class']==1],bins=50,color='red')
    sns.distplot(data[col][data['Class']==0],bins=50,color='blue')
    ax.set_ylabel('Density')
    ax.set_title(str(col))
    ax.set_xlabel('')
plt.show()
    
#对数据进行共线性筛查
correlation_table = data.corr()
plt.figure(figsize=(48,24))
sns.heatmap(correlation_table,linewidths=0.1,vmax=1.0,square=True,linecolor='white',annot=True)
plt.show()
#通过图形展示，可以看出自变量之间不存在共线性
#查看数据是否存在分类不平衡问题
count_classes = pd.value_counts(data['Class'], sort = True)
count_classes.plot(kind = 'bar')
plt.title("Fraud class histogram")
plt.xlabel("Class")
plt.ylabel("Frequency")
print(f'无欺诈行为样本占比：{round((count_classes[0]/count_classes.sum())*100,2)}%')
print(f'有欺诈行为样本占比：{round((count_classes[1]/count_classes.sum())*100,2)}%')
#通过图形展示，可以判断数据集存在分类不平衡的问题

#对样本进行随机欠取样
number_records_fraud = len(data[data.Class == 1])
fraud_indices = np.array(data[data.Class == 1].index)
normal_indices = data[data.Class == 0].index
random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)
random_normal_indices = np.array(random_normal_indices)
under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])
under_sample_data = data.iloc[under_sample_indices,:]
balanced_sample=under_sample_data.sample(frac=1,random_state=42).reset_index(drop=True)

# 显示比例
print("Percentage of normal transactions: ", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))
print("Percentage of fraud transactions: ", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))
print("Total number of transactions in resampled data: ", len(under_sample_data))

#数据预处理
balanced_sample[['Time','Amount','Time_min','Time_hour']]=StandardScaler().fit_transform(balanced_sample[['Time','Amount','Time_min','Time_hour']])
#保存预处理好的数据
balanced_sample.to_csv('balanced_sample.csv',index=False)
#使用留一法进行数据集划分，验证集比例：30%
X= balanced_sample.drop('Class',axis=1)
y= balanced_sample['Class']
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state = 42)
print(f'the shape of X training set is: {X_train.shape}')
print(f'the shape of X testing set is: {X_test.shape}')
#设置交叉验证
cv=StratifiedKFold(n_splits=3,shuffle=True)
#构建逻辑回归模型
log_params={'penalty':['l1','l2'],
            'C':[0.001,0.01,0.1,1,10,100,1000]}
grid_log_clf=GridSearchCV(LogisticRegression(solver='liblinear'),log_params,cv=cv,n_jobs=16,scoring='roc_auc',verbose=0,refit=True)
pipe_logclf=Pipeline([
        ('logistic_grid',grid_log_clf)])
pipe_logclf.fit(X_train,y_train)
print('done')
pipe_logclf.named_steps['logistic_grid'].best_params_

#定义一个函数，方便查看模型在训练集和验证集上的各种指标
def check_prefprmance(model,X_train,X_test,y_train,y_test):
    y_train_predict=model.predict(X_train)
    print(f'\nOn training datasets:\n')
    print(f'accuracy score is :{accuracy_score(y_train,y_train_predict)}')
    print(f'precision socre is :{precision_score(y_train,y_train_predict)}')
    print(f'recall score is :{recall_score(y_train,y_train_predict)}')
    print(f'auc:{roc_auc_score(y_train,y_train_predict)}')
    y_test_predict=model.predict(X_test)
    print(f'\nOn testing datasets:\n')
    print(f'accuracy score is :{accuracy_score(y_test,y_test_predict)}')
    print(f'precision socre is :{precision_score(y_test,y_test_predict)}')
    print(f'recall score is :{recall_score(y_test,y_test_predict)}')
    print(f'auc:{roc_auc_score(y_test,y_test_predict)}')

#查看逻辑回归模型的表现
check_prefprmance(pipe_logclf,X_train,X_test,y_train,y_test)
    
#构建随机森林模型
rf_model=RandomForestClassifier(criterion='gini',n_jobs=16,n_estimators=1000,random_state=133)
parameters={'max_features':['auto',0.5,0.8,0.9],
            'max_depth':[3,6,9]}
rf_grid_search=GridSearchCV(rf_model,parameters,n_jobs=16,cv=cv,scoring='roc_auc',verbose=0,refit=True)
pipe_rfclf=Pipeline([
        ('rf_grid',rf_grid_search)])
pipe_rfclf.fit(X_train,y_train)
print('done')

pipe_rfclf.named_steps['rf_grid'].best_params_
#查看随机森林模型的表现
check_prefprmance(pipe_rfclf,X_train,X_test,y_train,y_test)

#构建xgboost模型
xgb_model=xgb.XGBClassifier(objective='binary:hinge',
                            nthread=8,
                            booster='gbtree',
                            n_estimators=500,
                            learning_rate=0.01)
xgb_paras={'max_depth':[3,5],
           'subsample':[0.6,0.9],
           'colsample_bytree':[0.3,0.5,0.6,0.8],
           'reg_alpha':[0.01,0.05,0.1,1,10]}
xgb_grid_search=GridSearchCV(xgb_model,xgb_paras,n_jobs=8,cv=cv,scoring='roc_auc',verbose=2,refit=True)
pipe_xgbclf=Pipeline([
        ('xgb_clf',xgb_grid_search)])
pipe_xgbclf.fit(X_train,y_train)
print('done')
pipe_xgbclf.named_steps['xgb_clf'].best_params_
xgb_final=pipe_xgbclf.named_steps['xgb_clf'].best_estimator_
xgb.plot_importance(xgb_final,max_num_features=40,height=0.8)
#查看xgboost模型的表现
check_prefprmance(pipe_xgbclf,X_train,X_test,y_train,y_test)
#通过对比AUC值，最好的模型是xgboost模型
